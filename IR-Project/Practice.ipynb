{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc916c6a-5564-4b55-b58c-7506161b1e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ifti/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ifti/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ifti/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/ifti/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = [word for word in stopwords.words('english')] \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.stem import PorterStemmer     # for stemming\n",
    "from nltk.stem import WordNetLemmatizer # for lemmatization\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556f201-19b9-4cb2-a46f-d8480472ca8c",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01359884-eed1-41e6-b843-2060e8ea8d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents = 1460.\n",
      "\n",
      "18 Editions of the Dewey Decimal Classifications Comaromi, J.P. The present study is a history of the DEWEY Decimal Classification.  The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed.  In spite of the DDC's long and healthy life, however, its full story has never been told.  There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad. \n"
     ]
    }
   ],
   "source": [
    "with open('CISI.ALL') as f:\n",
    "    lines = \"\"\n",
    "    for l in f.readlines():\n",
    "        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
    "    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
    "    \n",
    "    \n",
    "# # print n lines\n",
    "# n = 10\n",
    "# for l in lines[:n]:\n",
    "#     print(l)\n",
    "    \n",
    "    \n",
    "doc_set = {}\n",
    "doc_id = \"\"\n",
    "doc_text = \"\"\n",
    "for l in lines:\n",
    "    if l.startswith(\".I\"):\n",
    "        doc_id = l.split(\" \")[1].strip()\n",
    "    elif l.startswith(\".X\"):\n",
    "        doc_set[doc_id] = doc_text.lstrip(\" \")\n",
    "        doc_id = \"\"\n",
    "        doc_text = \"\"\n",
    "    else:\n",
    "        doc_text += l.strip()[3:] + \" \" # The first 3 characters of a line can be ignored.\n",
    "\n",
    "# Print something to see the dictionary structure, etc.\n",
    "print(f\"Number of documents = {len(doc_set)}\" + \".\\n\")\n",
    "print(doc_set[\"1\"]) # note that the dictionary indexes are strings, not numbers. \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69738666-a396-4a75-978b-629fbd161363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queries = 112.\n",
      "\n",
      "What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?\n"
     ]
    }
   ],
   "source": [
    "with open('CISI.QRY') as f:\n",
    "    lines = \"\"\n",
    "    for l in f.readlines():\n",
    "        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
    "    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
    "    \n",
    "qry_set = {}\n",
    "qry_id = \"\"\n",
    "for l in lines:\n",
    "    if l.startswith(\".I\"):\n",
    "        qry_id = l.split(\" \")[1].strip()\n",
    "    elif l.startswith(\".W\"):\n",
    "        qry_set[qry_id] = l.strip()[3:]\n",
    "        qry_id = \"\"\n",
    "    \n",
    "# Print something to see the dictionary structure, etc.\n",
    "print(f\"Number of queries = {len(qry_set)}\" + \".\\n\")\n",
    "print(qry_set[\"1\"]) # note that the dictionary indexes are strings, not numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4e90dab-6be9-4517-9464-4c83cbdb7f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1     28\t0\t0.000000\n",
      "     1     35\t0\t0.000000\n",
      "     1     38\t0\t0.000000\n",
      "     1     42\t0\t0.000000\n",
      "     1     43\t0\t0.000000\n",
      "     1     52\t0\t0.000000\n",
      "     1     65\t0\t0.000000\n",
      "     1     76\t0\t0.000000\n",
      "     1     86\t0\t0.000000\n",
      "     1    150\t0\t0.000000\n",
      "     1    189\t0\t0.000000\n",
      "     1    192\t0\t0.000000\n",
      "     1    193\t0\t0.000000\n",
      "     1    195\t0\t0.000000\n",
      "     1    215\t0\t0.000000\n",
      "     1    269\t0\t0.000000\n",
      "     1    291\t0\t0.000000\n",
      "     1    320\t0\t0.000000\n",
      "     1    429\t0\t0.000000\n",
      "     1    465\t0\t0.000000\n",
      "     1    466\t0\t0.000000\n",
      "     1    482\t0\t0.000000\n",
      "     1    483\t0\t0.000000\n",
      "     1    510\t0\t0.000000\n",
      "     1    524\t0\t0.000000\n",
      "     1    541\t0\t0.000000\n",
      "     1    576\t0\t0.000000\n",
      "     1    582\t0\t0.000000\n",
      "     1    589\t0\t0.000000\n",
      "     1    603\t0\t0.000000\n",
      "     1    650\t0\t0.000000\n",
      "     1    680\t0\t0.000000\n",
      "     1    711\t0\t0.000000\n",
      "     1    722\t0\t0.000000\n",
      "     1    726\t0\t0.000000\n",
      "     1    783\t0\t0.000000\n",
      "     1    813\t0\t0.000000\n",
      "     1    820\t0\t0.000000\n",
      "     1    868\t0\t0.000000\n",
      "     1    869\t0\t0.000000\n",
      "     1    894\t0\t0.000000\n",
      "     1   1162\t0\t0.000000\n",
      "     1   1164\t0\t0.000000\n",
      "     1   1195\t0\t0.000000\n",
      "     1   1196\t0\t0.000000\n",
      "     1   1281\t0\t0.000000\n",
      "\n",
      "Number of mappings = 46.\n",
      "\n",
      "['28', '35', '38', '42', '43', '52', '65', '76', '86', '150', '189', '192', '193', '195', '215', '269', '291', '320', '429', '465', '466', '482', '483', '510', '524', '541', '576', '582', '589', '603', '650', '680', '711', '722', '726', '783', '813', '820', '868', '869', '894', '1162', '1164', '1195', '1196', '1281']\n"
     ]
    }
   ],
   "source": [
    "def mapping(query_id):\n",
    "    rel_set = {}\n",
    "    with open('CISI.REL') as f:\n",
    "        for l in f.readlines():\n",
    "            qry_id = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[0]\n",
    "            doc_id = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[-1]\n",
    "            if qry_id in rel_set:\n",
    "                rel_set[qry_id].append(doc_id)\n",
    "            else:\n",
    "                rel_set[qry_id] = []\n",
    "                rel_set[qry_id].append(doc_id)\n",
    "            if qry_id == query_id:\n",
    "                print(l.strip(\"\\n\"))\n",
    "\n",
    "    # Print something to see the dictionary structure, etc.\n",
    "    print(f\"\\nNumber of mappings = {len(rel_set[query_id])}\" + \".\\n\")\n",
    "    print(rel_set[query_id]) # note that the dictionary indexes are strings, not numbers.\n",
    "    return qry_set ,rel_set\n",
    "    \n",
    "query_id = str(1)\n",
    "qry_set ,rel_set= mapping(query_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02c4f7fd-1084-46b6-96f3-33efec4ab159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qry_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54527375-6ca4-4845-9fbf-bac2bc79ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_set['28']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbb575ca-50ce-46f0-9db8-6db06c9ee982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comparisons of Four Types of Lexical Indicators of Content Rath, G.J. Resnick, A. Savage, T.R. An experiment was conducted to determine which of four types of lexical indicators of content could be utilized best by subjects to determine relevant from irrelevant documents and to answer a set of 100 questions.  The results indicate that there were no major differences between the groups using complete text and abstracts to select relevant documents, but the group utilizing the complete text obtained a significantly higher score on the examination. '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_set['35']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420ecc5-531b-4445-83cf-54e5ed9b39f8",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57df03a7-e3e2-43fb-9888-d32d2d393816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    pos_tagged_tokens = nltk.pos_tag(tokens)\n",
    "    return pos_tagged_tokens\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower().strip()\n",
    "    text = tags(text)\n",
    "    punc = \"''!()-[]{};:'\\,<>./?@#$%^&*_~''\"\n",
    "    processed = \"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    for word_ in text:\n",
    "        word = word_[0]\n",
    "        tag = word_[1]\n",
    "        \n",
    "        if word in stopwords:\n",
    "            continue\n",
    "        for i in punc:\n",
    "            word = word.replace(i, '')\n",
    "        \n",
    "        word = stemmer.stem(word)      # stemming the words\n",
    "        processed = processed + word\n",
    "        processed = processed + \" \"\n",
    "    processed = processed.rstrip()\n",
    "    return processed    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "750e5d89-2608-403a-9fef-1406fde4749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_qry_set = {}\n",
    "processed_doc_set = {}\n",
    "voc = []\n",
    "\n",
    "for key, value in qry_set.items():\n",
    "    processed = preprocess(value)\n",
    "    processed_qry_set[key] = processed\n",
    "\n",
    "for key, value in doc_set.items():\n",
    "    processed = preprocess(value)\n",
    "    processed_doc_set[key] = processed\n",
    "    voc.append(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "beeec778-43c5-467b-b881-2e70ad65221a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'use made technic librari slater  m report analysi 6300 act use 104 technic librari unit kingdom  librari use one aspect wider pattern inform use  inform transfer librari restrict use document  take account document use outsid librari  still less inform transfer oral person person  librari act channel proport situat inform transfer  take technic inform transfer whole  doubt proport major one  user technic inform  particularli technolog rather scienc  visit librari rare  reli desk collect handbook  current period person contact colleagu peopl organ  even regular librari user also receiv inform way'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2c92eb88-2b29-4025-a32c-2d77cbf30491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18 edit dewey decim classif comaromi  jp present studi histori dewey decim classif  first edit ddc publish 1876  eighteenth edit 1971  futur edit continu appear need  spite ddc s long healthi life  howev  full stori never told  biographi dewey briefli describ system  first attempt provid detail histori work spur growth librarianship countri abroad'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_doc_set['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "713e6a2a-f9fd-46d8-b765-02d07eb5c6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'problem concern make descript titl  difficulti involv automat retriev articl approxim titl  usual relev content articl titl'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_qry_set['1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4241bfe4-66ff-498d-85b1-e45895f85afb",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e88fc3f3-da1b-4a5a-978f-7c507c79a84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer()\n",
    "vec.fit(voc)\n",
    "= 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "401e16bd-77b3-48e2-b627-ae351e502530",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors = {}\n",
    "\n",
    "for key, value in processed_doc_set.items():\n",
    "    vector = vec.transform([value])\n",
    "    \n",
    "    doc_vectors[key] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "066b50bd-35e0-4461-a1cc-795d5c0f7e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_vectors['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2582fb4a-7a54-4628-8338-a2001ddf0937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is information science?  Give definitions where possible.'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qry_set['3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2512c0-a86f-432e-a594-02a79d00f133",
   "metadata": {},
   "source": [
    "# Cosine Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ab1f0c05-5c38-4635-9aed-8e398d5ef413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5628054992165529, '448'), (0.4743560016626262, '422'), (0.40430700772077716, '635'), (0.39152609071057776, '485'), (0.3716336049278343, '566'), (0.3532262501320893, '570')]\n"
     ]
    }
   ],
   "source": [
    "qn = '111'\n",
    "query = qry_set[qn]\n",
    "# print(query)\n",
    "query = preprocess(query)\n",
    "query = [query]\n",
    "# print('preprocessed : ',query)\n",
    "\n",
    "vector = vec.transform(query)\n",
    "\n",
    "# print(vector.toarray()[0])\n",
    "# print(value.toarray()[0])\n",
    "\n",
    "# consine similarity\n",
    "similar = []\n",
    "for key, value in doc_vectors.items():\n",
    "    # print(vector, value)\n",
    "    product = sum(vector.toarray()[0] * value.toarray()[0])\n",
    "    similar.append((product, key))\n",
    "    \n",
    "similar = sorted(similar, reverse=True)\n",
    "k =10\n",
    "if len(rel_set[qn]) < k:\n",
    "    k = len(rel_set[qn])\n",
    "similar = similar[: k]\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ebded-510a-4c7d-818f-46190726384c",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b03283cd-ce3c-499d-a928-09d3f5dfaefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9\n",
      "DCG :  3643.1641290251723\n"
     ]
    }
   ],
   "source": [
    "from math import log2\n",
    "\n",
    "count = 0\n",
    "for i in similar:\n",
    "    if i[1] in rel_set[qn]:\n",
    "        count += 1\n",
    "print(\"Accuracy : \", count/len(similar))\n",
    "\n",
    "\n",
    "dcg = 0\n",
    "c = 1\n",
    "for i in similar:\n",
    "    r = int(i[1])\n",
    "    if c >= 2:\n",
    "        r = r/log2(c)\n",
    "    dcg += r\n",
    "    c += 1\n",
    "print(\"DCG : \",dcg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f3b989-e1b9-4895-a65e-fe52d5a4a30c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
