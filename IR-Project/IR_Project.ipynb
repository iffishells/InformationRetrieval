{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fd3db1e-65c8-4bfb-8927-ca04caf7bd38",
   "metadata": {},
   "source": [
    "## Group Members\n",
    "    Ahmed Abbasi (18P-0040)\n",
    "    Muhammad Iftikhar (18P-0054)\n",
    "    Sabir Hussain (18P-0085) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bec1f969-54ed-4c4f-a851-04f5a1042c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".I 1\n",
      ".T 18 Editions of the Dewey Decimal Classifications\n",
      ".A Comaromi, J.P.\n",
      ".W The present study is a history of the DEWEY Decimal Classification.  The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed.  In spite of the DDC's long and healthy life, however, its full story has never been told.  There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad.\n",
      ".X 1\t5\t1 92\t1\t1 262\t1\t1 556\t1\t1 1004\t1\t1 1024\t1\t1 1024\t1\t1\n",
      "Number of documents = 1460.\n",
      "\n",
      "18 Editions of the Dewey Decimal Classifications Comaromi, J.P. The present study is a history of the DEWEY Decimal Classification.  The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed.  In spite of the DDC's long and healthy life, however, its full story has never been told.  There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad. \n"
     ]
    }
   ],
   "source": [
    "with open('CISI.ALL') as f:\n",
    "    lines = \"\"\n",
    "    for l in f.readlines():\n",
    "        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
    "    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
    "    \n",
    "# print n lines\n",
    "n = 5\n",
    "for l in lines[:n]:\n",
    "    print(l)\n",
    "    \n",
    "doc_set = {}\n",
    "doc_id = \"\"\n",
    "doc_text = \"\"\n",
    "for l in lines:\n",
    "    if l.startswith(\".I\"):\n",
    "        doc_id = l.split(\" \")[1].strip()\n",
    "    elif l.startswith(\".X\"):\n",
    "        doc_set[doc_id] = doc_text.lstrip(\" \")\n",
    "        doc_id = \"\"\n",
    "        doc_text = \"\"\n",
    "    else:\n",
    "        doc_text += l.strip()[3:] + \" \" # The first 3 characters of a line can be ignored.\n",
    "\n",
    "# Print something to see the dictionary structure, etc.\n",
    "print(f\"Number of documents = {len(doc_set)}\" + \".\\n\")\n",
    "print(doc_set[\"1\"]) # note that the dictionary indexes are strings, not numbers. \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06b8dcf-0192-4741-a5ca-178fe2fe190b",
   "metadata": {},
   "source": [
    "## Repeat with Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee6c8265-1290-4fe2-935b-65ca9e85729d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queries = 112.\n",
      "\n",
      "What is information science?  Give definitions where possible.\n"
     ]
    }
   ],
   "source": [
    "with open('CISI.QRY') as f:\n",
    "    lines = \"\"\n",
    "    for l in f.readlines():\n",
    "        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
    "    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
    "    \n",
    "qry_set = {}\n",
    "qry_id = \"\"\n",
    "for l in lines:\n",
    "    if l.startswith(\".I\"):\n",
    "        qry_id = l.split(\" \")[1].strip()\n",
    "    elif l.startswith(\".W\"):\n",
    "        qry_set[qry_id] = l.strip()[3:]\n",
    "        qry_id = \"\"\n",
    "    \n",
    "# Print something to see the dictionary structure, etc.\n",
    "print(f\"Number of queries = {len(qry_set)}\" + \".\\n\")\n",
    "print(qry_set[\"3\"]) # note that the dictionary indexes are strings, not numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8f24c5-31d7-46db-acf8-b65a5c51cfbe",
   "metadata": {},
   "source": [
    "## Do the same with query => document MAPPING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f64a7c8-e006-40f2-b093-dca374dbdc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1     28\t0\t0.000000\n",
      "     1     35\t0\t0.000000\n",
      "     1     38\t0\t0.000000\n",
      "     1     42\t0\t0.000000\n",
      "     1     43\t0\t0.000000\n",
      "     1     52\t0\t0.000000\n",
      "     1     65\t0\t0.000000\n",
      "     1     76\t0\t0.000000\n",
      "     1     86\t0\t0.000000\n",
      "     1    150\t0\t0.000000\n",
      "     1    189\t0\t0.000000\n",
      "     1    192\t0\t0.000000\n",
      "     1    193\t0\t0.000000\n",
      "     1    195\t0\t0.000000\n",
      "     1    215\t0\t0.000000\n",
      "     1    269\t0\t0.000000\n",
      "     1    291\t0\t0.000000\n",
      "     1    320\t0\t0.000000\n",
      "     1    429\t0\t0.000000\n",
      "     1    465\t0\t0.000000\n",
      "     1    466\t0\t0.000000\n",
      "     1    482\t0\t0.000000\n",
      "     1    483\t0\t0.000000\n",
      "     1    510\t0\t0.000000\n",
      "     1    524\t0\t0.000000\n",
      "     1    541\t0\t0.000000\n",
      "     1    576\t0\t0.000000\n",
      "     1    582\t0\t0.000000\n",
      "     1    589\t0\t0.000000\n",
      "     1    603\t0\t0.000000\n",
      "     1    650\t0\t0.000000\n",
      "     1    680\t0\t0.000000\n",
      "     1    711\t0\t0.000000\n",
      "     1    722\t0\t0.000000\n",
      "     1    726\t0\t0.000000\n",
      "     1    783\t0\t0.000000\n",
      "     1    813\t0\t0.000000\n",
      "     1    820\t0\t0.000000\n",
      "     1    868\t0\t0.000000\n",
      "     1    869\t0\t0.000000\n",
      "     1    894\t0\t0.000000\n",
      "     1   1162\t0\t0.000000\n",
      "     1   1164\t0\t0.000000\n",
      "     1   1195\t0\t0.000000\n",
      "     1   1196\t0\t0.000000\n",
      "     1   1281\t0\t0.000000\n",
      "\n",
      "Number of mappings = 76.\n",
      "\n",
      "['28', '35', '38', '42', '43', '52', '65', '76', '86', '150', '189', '192', '193', '195', '215', '269', '291', '320', '429', '465', '466', '482', '483', '510', '524', '541', '576', '582', '589', '603', '650', '680', '711', '722', '726', '783', '813', '820', '868', '869', '894', '1162', '1164', '1195', '1196', '1281']\n"
     ]
    }
   ],
   "source": [
    "rel_set = {}\n",
    "with open('CISI.REL') as f:\n",
    "    for l in f.readlines():\n",
    "        qry_id = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[0]\n",
    "        doc_id = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[-1]\n",
    "        if qry_id in rel_set:\n",
    "            rel_set[qry_id].append(doc_id)\n",
    "        else:\n",
    "            rel_set[qry_id] = []\n",
    "            rel_set[qry_id].append(doc_id)\n",
    "        if qry_id == \"1\":\n",
    "            print(l.strip(\"\\n\"))\n",
    "    \n",
    "# Print something to see the dictionary structure, etc.\n",
    "print(f\"\\nNumber of mappings = {len(rel_set)}\" + \".\\n\")\n",
    "print(rel_set[\"1\"]) # note that the dictionary indexes are strings, not numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf98ed80-f4cd-4ca1-bd07-4b09fba72630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qry_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb94ad4-ad41-49c1-baf8-9f661da4a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_set #[\"1281\"]) # note that the dictionary indexes are strings, not numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f38295c-978d-47dc-aa9e-868dbc5c2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45afdc90-d3a5-42c1-9630-341e2e326c01",
   "metadata": {},
   "source": [
    "# Data retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99bd6944-bcaf-4237-ba99-203fe54184a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ifti/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ifti/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ifti/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/ifti/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = [word for word in stopwords.words('english')] # stop words in spanish\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.stem import PorterStemmer     # for stemming\n",
    "from nltk.stem import WordNetLemmatizer # for lemmatization\n",
    "import numpy as np\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b655942-c0ac-4297-b830-ebf7c4bb6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    pos_tagged_tokens = nltk.pos_tag(tokens)\n",
    "    return pos_tagged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17469b82-6317-430c-8ef6-dcab24402c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower().strip()\n",
    "    text = tags(text)\n",
    "    punc = \"''!()-[]{};:'\\,<>./?@#$%^&*_~''\"\n",
    "    processed = \"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    for word_ in text:\n",
    "        word = word_[0]\n",
    "        tag = word_[1]\n",
    "        \n",
    "        if word in stopwords:\n",
    "            continue\n",
    "        for i in punc:\n",
    "            word = word.replace(i, '')\n",
    "        \n",
    "        word = stemmer.stem(word)      # stemming the words\n",
    "        processed = processed + word\n",
    "        processed = processed + \" \"\n",
    "    processed = processed.rstrip()\n",
    "    return processed    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64ddea5f-dc4f-48a2-8629-dc325e82e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_qry_set = {}\n",
    "processed_doc_set = {}\n",
    "voc = []\n",
    "\n",
    "for key, value in qry_set.items():\n",
    "    processed = preprocess(value)\n",
    "    processed_qry_set[key] = processed\n",
    "\n",
    "for key, value in doc_set.items():\n",
    "    processed = preprocess(value)\n",
    "    processed_doc_set[key] = processed\n",
    "    voc.append(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93e33bf2-1b46-4728-82b1-4f2d658db121",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f83efa8-39a4-44bc-bdd8-51b90655cbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer()\n",
    "vec.fit(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8957db54-f5db-4969-bf18-bcdc934b3be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors = {}\n",
    "\n",
    "for key, value in processed_doc_set.items():\n",
    "    vector = vec.transform([value])\n",
    "    \n",
    "    doc_vectors[key] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae001095-42d3-4fa1-9a1d-aae463416b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "649fdd44-c392-4835-a6ce-f207888e21e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is information science?  Give definitions where possible.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qry_set['3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a087c67e-089f-4568-829e-9903e4f534e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?\n"
     ]
    }
   ],
   "source": [
    "qn = '1'\n",
    "query = qry_set[qn]\n",
    "print(query)\n",
    "query = preprocess(query)\n",
    "query = [query]\n",
    "\n",
    "vector = vec.transform(query)\n",
    "\n",
    "similar = []\n",
    "for key, value in doc_vectors.items():\n",
    "    # print(vector.shape, value.shape)\n",
    "    product = sum(vector.toarray()[0] * value.toarray()[0])\n",
    "    similar.append((product, key))\n",
    "similar = sorted(similar, reverse=True)\n",
    "k = 10\n",
    "\n",
    "\n",
    "if len(rel_set[qn]) < 10:\n",
    "    k = len(rel_set[qn])\n",
    "similar = similar[: k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1cddadc-1884-42d4-9d10-e6187e43d8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in similar:\n",
    "    if i[1] in rel_set[qn]:\n",
    "        count += 1\n",
    "print(\"Accuracy : \", count/len(similar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0daed4a8-2104-4540-939c-10903fc8bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5749cf71-8d87-41d3-b5f3-337efcfd89a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar = [2, 2, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "67041e1d-d6f4-4e10-bfd0-3a4cc56b85bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3643.1641290251723"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcg = 0\n",
    "c = 1\n",
    "for i in similar:\n",
    "    r = int(i[1])\n",
    "    if c >= 2:\n",
    "        r = r/log2(c)\n",
    "    dcg += r\n",
    "    c += 1\n",
    "dcg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9438f6b8-6b53-46be-a5ab-dcf5936a40ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
