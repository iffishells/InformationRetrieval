{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b3c54cd-79e8-432b-a8e9-9cf59fa3b800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [Errno 11001] getaddrinfo failed>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = [word for word in stopwords.words('english')] # stop words in spanish\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.stem import PorterStemmer     # for stemming\n",
    "from nltk.stem import WordNetLemmatizer # for lemmatization\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ee1280-2f8f-494d-9002-3dc4289c5470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dataset\n",
    "corpus = open('dataset.txt', encoding=\"utf8\").read()\n",
    "corpus = corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9576abfc-4a4a-4c23-8685-2dc8b841c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    pos_tagged_tokens = nltk.pos_tag(tokens)\n",
    "    return pos_tagged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e28ab-96ce-408e-9116-04ee566d0bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "769f8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting on the bases of * that is in the end of every question answer pair\n",
    "corpus = corpus.split('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1d26af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "da4ab998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating the Questions from answers\n",
    "faq = []\n",
    "for i in corpus:\n",
    "    f = i.split('?')\n",
    "    faq.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "42eae81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4d9c69b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving questions in the keys list and answers in val list \n",
    "keys = []\n",
    "val = []\n",
    "\n",
    "for i in faq:\n",
    "    keys.append(i[0])\n",
    "    val.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b115c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "da106e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2e4af4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#updating keys and value pair by removing extra new line characters /n\n",
    "\n",
    "updated_keys = []\n",
    "for i in keys:\n",
    "    temp = i.strip('\\n')\n",
    "    updated_keys.append(temp)\n",
    "    \n",
    "updated_val = []\n",
    "for i in val:\n",
    "    temp = i.strip(' \\n')\n",
    "    updated_val.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9adb777-eca0-4f93-b2e7-d21021195798",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()  # stemmer for stemming the words\n",
    "lemma   = WordNetLemmatizer()\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "\n",
    "c = 0\n",
    "for tweet in updated_keys:\n",
    "    tweet = tweet.lower().strip()  # converting into lowercase and removing whitespaces\n",
    "    tweet = re.sub(r'pic.twitter.*$',\"\", tweet)\n",
    "    \n",
    "    tweet = re.sub('\\S*@\\S*\\s?', '', tweet) \n",
    "\n",
    "    # Removing new line characters\n",
    "    tweet = re.sub('\\s+', ' ', tweet) \n",
    "\n",
    "    # Removing distracting single quotes\n",
    "    tweet = re.sub(\"\\'\", \"\", tweet)  \n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet) \n",
    "    tweet = re.sub(r\"com\", \"\", tweet) \n",
    "    tweet = re.sub(r\"pic\", \"\", tweet) \n",
    "    tweet = re.sub(r\"twitter\", \"\", tweet) \n",
    "    tweet = re.sub(r\"%\", \"\", tweet) \n",
    "    tweet = re.sub(r\"#\", \"\", tweet) \n",
    "\n",
    "    tweet = tags(tweet)       #calling function\n",
    "    # print(\"tweet : \",tweet)\n",
    "    \n",
    "    t1 = \"\" # temp list \n",
    "    for word_ in tweet:\n",
    "        \n",
    "        word = word_[0]\n",
    "        check = word_[1]\n",
    "        #print(word)\n",
    "        \n",
    "        if 'V' in check or 'NN' in check: \n",
    "        \n",
    "            if word in stopwords:    # removing stopwords\n",
    "                continue   \n",
    "        \n",
    "            word = stemmer.stem(word)      # stemming the words\n",
    "            word = lemma.lemmatize(word, pos ='v')    # lemmatization on verbs\n",
    "        #print(\"stemmed : \",word)\n",
    "            t1 += word \n",
    "            t1 += \" \"\n",
    "    \n",
    "    t1 = t1.rstrip()\n",
    "    # print(\"\\nprocessed tweet : \",t1)\n",
    "    if len(t1) != 0:\n",
    "        X_train.append(t1)\n",
    "        Y_train.append(labels[c])\n",
    "    t1 = \"\"\n",
    "    c+= 1\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "85f1d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming dictionary of keys value pair\n",
    "question_and_answers = dict(zip(updated_keys,updated_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b254c5-a21f-4b4d-bf0f-23e0dd7d3416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6534d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_and_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cadc92a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 78)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(updated_keys), len(updated_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "38083771-b17a-4630-99ac-ce1c86c619a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer()\n",
    "vec.fit(updated_keys)\n",
    "X = vec.fit_transform(updated_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fddcac02-f287-40ef-a04f-4e30ed774173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbc = MultinomialNB()\n",
    "nbc.fit(X, updated_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d406e265-03e1-4bea-bd27-c3054ca44b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 225)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4d2c0e22-c05d-41ca-8858-8c5d218e44e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Question :  what is FAST university?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer :  ['ans fast might be the oldest computer sciences university in pakistan â€“ it might also have one of the best faculty and programs in pakistan, but students studying in fast know that this university causes the most tasking time of your life.']\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Enter Question : \")\n",
    "question = question.lower()\n",
    "# print(question)\n",
    "question = [question]\n",
    "vector = vec.transform(question)\n",
    "\n",
    "print(\"Answer : \", nbc.predict(vector))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
